<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Karla Monterrubio-Gómez, Nathan Constantine-Cooke, and Catalina Vallejos" />

<meta name="date" content="2024-01-11" />

<title>Approaches based on a discrete survival times specification</title>

<script src="Discrete_specification_files/header-attrs-2.24/header-attrs.js"></script>
<script src="Discrete_specification_files/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="Discrete_specification_files/bootstrap-3.3.5/css/simplex.min.css" rel="stylesheet" />
<script src="Discrete_specification_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="Discrete_specification_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="Discrete_specification_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="Discrete_specification_files/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="Discrete_specification_files/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="Discrete_specification_files/tocify-1.9.1/jquery.tocify.js"></script>
<script src="Discrete_specification_files/navigation-1.1/tabsets.js"></script>
<script src="Discrete_specification_files/navigation-1.1/codefolding.js"></script>
<link href="Discrete_specification_files/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="Discrete_specification_files/highlightjs-9.12.0/highlight.js"></script>
<script src="https://kit.fontawesome.com/1339b11c04.js" crossorigin="anonymous"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>





<style type="text/css">
/* for pandoc --citeproc since 2.11 */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}

.tocify-subheader {
  display: inline;
}
.tocify-subheader .tocify-item {
  font-size: 0.95em;
}

</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div id = "nav">
  <ul>
    <li><a href="index.html">Home</a></li>
    <li><a href="DataPreparation.html">Data Preparation</a></li>
    <li><a href="CIF_specification.html">Cumulative Incidence</a></li>
    <li><a href="CS_specification.html">Cause Specific</a></li>
    <li><a href="Discrete_specification.html">Discrete</a></li>
    <li><a href="Others.html">Other</a></li>
    <li><a href="Predictions.html">Predictions</a></li>
    <li style="float:right"><a href="https://github.com/VallejosGroup/CompRisksVignettes"><i style="font-size: 20px; padding-top: 0px; padding-bottom: 0px;" class="fa-brands fa-github"></i></a></li>
  </ul>
</div>

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Approaches based on a discrete survival
times specification</h1>
<h4 class="author">Karla Monterrubio-Gómez, Nathan Constantine-Cooke,
and Catalina Vallejos</h4>
<h4 class="date">2024-01-11</h4>

</div>


<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>The dataset used here corresponds to the Hodgkin’s disease (HD) study
described in Pintilie, 2006. The data was loaded and pre-processed using
the script that is sourced below. The latter creates three data
objects:</p>
<ul>
<li><code>hd</code>: all the samples in the original data</li>
<li><code>hd_train</code>: a random sample of the data to be used as a
training set</li>
<li><code>hd_test</code>: a random sample of the data to be used as a
testing set</li>
</ul>
<p>Details about data pre-processing steps can be found <a
href="https://github.com/VallejosGroup/CompRisksVignettes/blob/main/Source/DataPreparation.Rmd">here</a></p>
<pre class="r"><code>source(&quot;../Data_prep/data_prep.R&quot;)
#&gt; The sourced script has been used to load and pre-process the data.
#&gt; The latter converts appropriate variables into factors.
#&gt; Additionally, we randomly split the data into training and testing sets, 
#&gt; enabling us to evaluate out-of-sample predictive performance when comparing different approaches.</code></pre>
<p>The following sections illustrate the usage of methods that use
discrete time specification when modelling competing risks data.</p>
</div>
<div id="bart" class="section level1">
<h1>BART</h1>
<p>BART has a well documented vignette (<span
class="citation">Sparapani, Spanbauer, and McCulloch (<a
href="#ref-sparapani2021">2021</a>)</span>). Here, we focus only on
demonstrating its usage for a CR setting, which corresponds to Section
5.3 in <span class="citation">Sparapani, Spanbauer, and McCulloch (<a
href="#ref-sparapani2021">2021</a>)</span>. In the following, we fit the
model with the two different likelihood formulations to compare the
obtained estimates.</p>
<p>The first step is to recast the data creating dummy variables for all
categorical covariates. This is done for both train and test sets:</p>
<pre class="r"><code>library(nnet)
library(survival)
library(BART)
#&gt; Loading required package: nlme
#&gt; 
#&gt; Attaching package: &#39;nlme&#39;
#&gt; The following object is masked from &#39;package:dplyr&#39;:
#&gt; 
#&gt;     collapse
library(stats)

xtrain = model.matrix(~. , hd_train[,c(1:6)])[,-1]
xtest = model.matrix(~. , hd_test[,c(1:6)])[,-1]</code></pre>
<div id="model-formulation-1" class="section level2">
<h2>Model formulation 1</h2>
<p>The first method employs two binary likelihoods. The first one is a
BART survival model for the time to the first event and the second model
accounts for the probability of the event being of type <span
class="math inline">\(k=1\)</span> given that the it occurred. The user
can fit the model by using function <code>crisk2.bart()</code>. Note
that the required binary event indicators <span
class="math inline">\(y_{ijk}\)</span> can be constructed beforehand
with <code>surv.pre.bart()</code> and passed to the function using the
<code>y.train</code> argument. Instead, here we pass arguments
<code>times</code> and <code>delta</code> which will construct event
indicators internally. If we are interested in predictions, the test set
can be passed directly when fitting the model through the argument
<code>x.test</code>. Arguments to control the MCMC sampler are:
<code>ndpost</code>, <code>nskip</code>, and <code>keepevery</code>.
Their functionality is documented in the help file for the
<code>crisk2.bart()</code> function.</p>
<pre class="r"><code>set.seed(99)
bart1 &lt;- crisk2.bart(x.train = xtrain, 
                     times = hd_train$time,   # needed if ytrain is not provided
                     delta = hd_train$status, # needed if ytrain is not provided
                     x.test = xtest, 
                     sparse = FALSE,          # set equal TRUE for variable selection 
                     type = &#39;pbart&#39;,
                     ntree = 30, numcut = 100, 
                     ndpost = 500, nskip = 500, keepevery = 5)</code></pre>
<p>Note that the code shown above does not use multi-threading, but BART
permits its usage by using <code>mc.crisk2.bart()</code> function
instead of <code>crisk2.bart()</code>.</p>
<p>Studying convergence diagnosis of the MCMC chains is key to ensure
the predictions are valid. For continuous outcomes, this can be done
using the standard deviation parameter (<span
class="math inline">\(\sigma\)</span>) that is estimated by BART via the
<code>wbart()</code> function. Convergence assessment is more
challenging when using BART for survival outcomes. If there is a single
event type and the model was fitted using <code>surv.bart()</code>, then
convergence can be monitored using its <code>yhat.train</code> output.
However, as <code>yhat.train</code> is high-dimensional (there is one
column for each person-period pair), examples in the BART library
suggest to randomly select a subset of individuals and visualise
convergence diagnostics associated to their associated estimates. Here,
we will randomly select 5 individuals.</p>
<p>Generally, convergence would be assessed on estimates generated for
the training data. However, if there are multiple event types and
<code>crisk2.bart()</code> was used to fit the model,
<code>yhat.train</code> is not present in the output provided by the
current implementation (the same occurs for <code>crisk.bart()</code>).
Here we explore two possible strategies.</p>
<p>First, we use the posterior predictive distribution for the test
dataset which was calculated based on MCMC draws generated for the
training dataset. The following code visualises MCMC draws obtained for
<code>yhat.test</code> oftained for the first three individuals in the
test set (first time-period only)</p>
<pre class="r"><code>n.times &lt;- length(bart1$times)
# Select 5 random individuals
set.seed(10)
aux &lt;- sample(seq_len(nrow(hd_test)), size = 5)

for(i in aux) {
  plot(bart1$yhat.test[ , (i-1)*n.times + 1], type = &quot;l&quot;)
}</code></pre>
<p><img src="Discrete_specification_files/figure-html/unnamed-chunk-4-1.png" width="672" /><img src="Discrete_specification_files/figure-html/unnamed-chunk-4-2.png" width="672" /><img src="Discrete_specification_files/figure-html/unnamed-chunk-4-3.png" width="672" /><img src="Discrete_specification_files/figure-html/unnamed-chunk-4-4.png" width="672" /><img src="Discrete_specification_files/figure-html/unnamed-chunk-4-5.png" width="672" /></p>
<p>We can use Geweke diagnostics to assess converge across all
time-points for our randomly selected individuals.</p>
<pre class="r"><code># code adapted from the example in `demo(&quot;geweke.lung.surv.bart&quot;, package = &quot;BART&quot;)`
mycol &lt;- 0
for(i in aux) {
  mycol &lt;- mycol + 1
  # selects samples for individual i across all time-points
  post.mcmc &lt;- bart1$yhat.test[ , (i-1)*n.times + seq_len(n.times)]
  # calculates the geweke diagnostic
  z &lt;- gewekediag(post.mcmc)$z
  # to set the limits in the plot below
  y &lt;- max(c(4, abs(z)))

  ## plot the z scores vs. time for each patient
  if(i==aux[1]) plot(bart1$times, z, ylim=c(-y, y), type=&#39;l&#39;,
                  xlab=&#39;t&#39;, ylab=&#39;z&#39;)
      else lines(bart1$times, z, type=&#39;l&#39;, col = mycol)
  lines(bart1$times, rep(1.96, n.times), type=&#39;l&#39;, lty=2)
  lines(bart1$times, rep(-1.96, n.times), type=&#39;l&#39;, lty=2)
}</code></pre>
<p><img src="Discrete_specification_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>Alternatively, when contacting the authors to ask their advice about
this, they suggested an alternative strategy. This requires fitting a
new model, using the training data as a test set
(i.e. <code>x.test = xtrain</code>). The code required to this is
provided below.</p>
<pre class="r"><code>set.seed(99)
bart1.chains &lt;- crisk2.bart(x.train = xtrain, 
                     times = hd_train$time,   # needed if ytrain is not provided
                     delta = hd_train$status, # needed if ytrain is not provided
                     x.test = xtrain,         
                     sparse = FALSE,          # set equal TRUE for variable selection 
                     type = &#39;pbart&#39;,
                     ntree = 30, numcut = 100, 
                     ndpost = 500, nskip = 500, keepevery = 5)</code></pre>
<p>Similar plots for the Geweke diagnostic criteria can be then
generated using the code above, replacing <code>bart1</code> by
<code>bart1.chains</code>.</p>
<p>This, however, can be very time consuming — particularly for large
datasets or when the number of unique event times is large. Moreover,
this would assess MCMC convergence in a different chain to what is
contained in <code>bart1</code>. Another option would be to use the
<code>predict()</code> function, using the training dataset as test
data. This allows us to obtain estimates
(e.g. <code>surv.test.mean</code>) for individuals in the training
set.</p>
<pre class="r"><code># prepare the data to the format required by BART
# The training data is used as test dataset
set.seed(99)
pre &lt;- surv.pre.bart(x.train = xtrain, x.test = xtrain,
                     times = hd_train$time, delta = hd_train$status)
# generate predictions using 
pred.train &lt;- predict(bart1, newdata = pre$tx.test, newdata2 = pre$tx.test)</code></pre>
<p>As before, the Geweke diagnostic criteria can be applied:</p>
<pre class="r"><code># code adapted from the example in `demo(&quot;geweke.lung.surv.bart&quot;, package = &quot;BART&quot;)`
mycol &lt;- 0
for(i in aux) {
  mycol &lt;- mycol + 1
  # selects samples for individual i across all time-points
  post.mcmc &lt;- pred.train$yhat.test[ , (i-1)*n.times + seq_len(n.times)]
  # calculates the geweke diagnostic
  z &lt;- gewekediag(post.mcmc)$z
  # to set the limits in the plot below
  y &lt;- max(c(4, abs(z)))

  ## plot the z scores vs. time for each patient
  if(i==aux[1]) plot(pred.train$times, z, ylim=c(-y, y), type=&#39;l&#39;,
                  xlab=&#39;t&#39;, ylab=&#39;z&#39;)
      else lines(pred.train$times, z, type=&#39;l&#39;, col = mycol)
  lines(pred.train$times, rep(1.96, n.times), type=&#39;l&#39;, lty=2)
  lines(pred.train$times, rep(-1.96, n.times), type=&#39;l&#39;, lty=2)
}</code></pre>
<p><img src="Discrete_specification_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>In both cases, we notice that the Geweke statistics exceed the <span
class="math inline">\(95\%\)</span> limits several times, suggesting the
chains have not converged. Thus, the MCMC should be run for a longer
number of iterations to obtain valid estimates. In practice, this means
that <code>nskip</code> should be increased. However, to avoid long
running times when compiling this vignette, this is left as an exercise
to the reader.</p>
<p>The remaining of this vignette will continue as if the sampler had
converged.</p>
<p>CIFs for the subjects in the test set can be obtained through
<code>cif.test.mean()</code>. This provides the posterior mean across
MCMC samples. In addition, credible intervals can be computed from the
samples saved in <code>cif.test</code>. First, we re-organised the
predicted CIF for cause 1 for the test dataset. The constructed matrix
contains one row per subject and the columns correspond to the unique
time points at which it is evaluated. Second, we compute 95% credible
intervals.</p>
<pre class="r"><code>cif.pred &lt;- matrix(bart1$cif.test.mean, nrow=nrow(xtest), byrow = TRUE )

# Compute 95% credible intervals and put in matrix format:
cif.025 &lt;- apply(bart1$cif.test, 2, quantile, probs = 0.025) 
cif.025 &lt;- matrix(cif.025, nrow=nrow(xtest), byrow = TRUE)
cif.975 &lt;- apply(bart1$cif.test, 2, quantile, probs = 0.975) 
cif.975 &lt;- matrix(cif.975, nrow=nrow(xtest), byrow = TRUE)</code></pre>
<p>We show CIF curves for the first (red) and second (blue) individuals
in the test set along with its corresponding credible intervals:</p>
<pre class="r"><code>par(mar = c(4, 4, 2, 0.1))

plot(bart1$times,
     cif.pred[1,],
     type = &quot;l&quot;,
     col = &quot;red&quot;,
     ylim = c(0, 0.6),
     xlab = &quot;Time (years)&quot;,
     ylab = &quot;Cumulative incidence&quot;)
points(bart1$times,cif.025[1,], col = &quot;red&quot;, type =&#39;s&#39;, lwd = 1, lty = 2)
points(bart1$times,cif.975[1,], col = &quot;red&quot;, type = &#39;s&#39;, lwd = 1, lty = 2)
lines(bart1$times,  cif.pred[2,], col=&quot;blue&quot;)
points(bart1$times,cif.025[2,], col = &quot;blue&quot;, type =&#39;s&#39;, lwd = 1, lty = 2)
points(bart1$times,cif.975[2,], col = &quot;blue&quot;, type = &#39;s&#39;, lwd = 1, lty = 2)
legend(&quot;bottomright&quot;, legend = c(&quot;Patient 1&quot;, &quot;Patient 2&quot;),
       lty = c(1,1), col = c(&quot;red&quot;, &quot;blue&quot;))</code></pre>
<p><img src="Discrete_specification_files/figure-html/unnamed-chunk-10-1.png" width="576" /></p>
<p>Similar to other approaches, BART permits to do predictions of the
CIF at a specific time point (e.g. <span
class="math inline">\(t=5\)</span> years) for a new dataset
(e.g. <code>hd_test</code>). Note that predictions are only provided for
time-points present in the training dataset. Below, we show results for
the first 5 subjects in the test set.</p>
<pre class="r"><code>BART1.pred &lt;- matrix(bart1$cif.test.mean, nrow=nrow(xtest), byrow = TRUE )
BART1.pred[1:5, which(bart1$times == 5)]
#&gt; [1] 0.3200795 0.3458437 0.2952182 0.2691998 0.2547399</code></pre>
<p>Note also that if a new test dataset is available, one can do
predictions afterwards by making a call to the
<code>predict.crisk2bart()</code> function. For instance:</p>
<pre class="r"><code>set.seed(99)
pre &lt;- surv.pre.bart(x.train=xtrain, x.test=xtest, 
                     times=hd_train$time, 
                     delta =hd_train$status)

bart1.pred &lt;- predict(bart1, newdata=pre$tx.test, newdata2=pre$tx.test)

# Same results are obtained if the same test dataset is used
cif.pred[1:4, 1:4]
#&gt;             [,1]       [,2]       [,3]       [,4]
#&gt; [1,] 0.012018387 0.02388410 0.03559916 0.04716553
#&gt; [2,] 0.013490303 0.02678276 0.03988044 0.05278634
#&gt; [3,] 0.010450391 0.02078480 0.03100457 0.04111104
#&gt; [4,] 0.009426601 0.01875810 0.02799552 0.03713985
matrix(bart1.pred$cif.test.mean, nrow=nrow(xtest), byrow = TRUE )[1:4, 1:4]
#&gt;             [,1]       [,2]       [,3]       [,4]
#&gt; [1,] 0.012018387 0.02388410 0.03559916 0.04716553
#&gt; [2,] 0.013490303 0.02678276 0.03988044 0.05278634
#&gt; [3,] 0.010450391 0.02078480 0.03100457 0.04111104
#&gt; [4,] 0.009426601 0.01875810 0.02799552 0.03713985</code></pre>
<div id="dart" class="section level3">
<h3>DART</h3>
<p>It is possible to employ a sparse Dirichlet prior for variable
selection (DART model). This will help us to determine variable
importance. In order to fit such model we use again
<code>crisk2.bart()</code> function and set the <code>sparse</code>
argument equal to <code>TRUE</code>.</p>
<pre class="r"><code>set.seed(99)
dart1 &lt;- crisk2.bart(x.train = xtrain, 
                     times = hd_train$time,   # needed if ytrain is not provided
                     delta = hd_train$status, # needed if ytrain is not provided
                     x.test = xtest, 
                     sparse = TRUE,          # set equal TRUE for variable selection 
                     type = &#39;pbart&#39;,
                     ntree = 30, numcut = 100, 
                     ndpost = 500, nskip = 500, keepevery = 5)  </code></pre>
<p>The output of the function is the same as discussed in the previous
section. For simplicity, we have not evaluated convergence here, but the
approach described above could be applied. CIF estimates can also be
obtained as shown before.</p>
<p>Here, we illustrate the new functionality provided by DART in terms
of variable selection. The plot below shows the estimated marginal
posterior probabilities of inclusion associated to each input
covariates:</p>
<pre class="r"><code>dart1$varprob.mean[-1]
#&gt;        age       sexM trtgivenRT  medwidsiN  medwidsiS  extranodY   clinstg2 
#&gt; 0.17246905 0.07388055 0.06406175 0.03695244 0.06917858 0.05304716 0.22277258

plot(dart1$varprob.mean[-1], 
     ylab=&#39;Selection Probability&#39;, 
     ylim=c(0, 1))
P &lt;- ncol(xtrain)    # use to set thereshold probability for each covariate
abline(h = 1/P, lty = 2)</code></pre>
<p><img src="Discrete_specification_files/figure-html/unnamed-chunk-14-1.png" width="576" /></p>
<pre class="r"><code>
dart1$varprob.mean[-1] &gt; 1/P
#&gt;        age       sexM trtgivenRT  medwidsiN  medwidsiS  extranodY   clinstg2 
#&gt;       TRUE      FALSE      FALSE      FALSE      FALSE      FALSE       TRUE</code></pre>
<p>According to the plot above only age and treatment are relevant (this
assumes a <span class="math inline">\(1/P\)</span> threshold). However,
note that these results should be interpreted with caution as
convergence diagnostics have not been applied.</p>
<p>As before, predictions of the CIF at <span
class="math inline">\(t=5\)</span> years for the test dataset
(<code>hd_test</code>) can also be obtained.</p>
<pre class="r"><code>DART1.pred &lt;- matrix(dart1$cif.test.mean, nrow=nrow(xtest), byrow = TRUE )
DART1.pred[1:5, which(dart1$times == 5)]
#&gt; [1] 0.2701254 0.3576845 0.2583587 0.2803809 0.2396327</code></pre>
</div>
</div>
<div id="model-formulation-2" class="section level2">
<h2>Model formulation 2</h2>
<p>This approach is discussed in Section 3.2 of <span
class="citation">Sparapani et al. (<a
href="#ref-Bart2020">2020</a>)</span> and fits also two separate BART
probit models. The first model, corresponds to the conditional
probability of a cause <span class="math inline">\(k=1\)</span> event at
a given time. The second, models the conditional probability of an event
of type <span class="math inline">\(k=2\)</span> at a specific time,
given that the individual is still at risk and did not experience a type
<span class="math inline">\(k=1\)</span> event. In this case, the model
is fit with function <code>crisk.bart()</code>:</p>
<pre class="r"><code>set.seed(99)
bart2 &lt;- crisk.bart(x.train = xtrain, times = hd_train$time, 
                    delta=hd_train$status,
                    x.test = xtest, 
                    sparse=FALSE, 
                    type=&#39;pbart&#39;,
                    ntree = 30, numcut = 100, 
                    ndpost = 500, nskip = 500, keepevery = 5)
# Parallel computation of the model is available using mc.crisk.bart</code></pre>
<p>The output is the same as in model formulation 1 and an analysis of
convergence can be performed as before. For simplicity, this is excluded
from this example.</p>
<p><strong>NOTE: we have used a small number of iterations and the MCMC
did not appear to converge. Therefore, the results shown below need to
be interpreted with caution.</strong></p>
<p>As before, we employ <code>cif.test.mean</code> to obtain CIFs for
the subjects in the test set along with 95% credible intervals.</p>
<pre class="r"><code>cif2.pred &lt;- matrix(bart2$cif.test.mean, nrow=nrow(xtest), byrow = TRUE )

# Compute 95% credible intervals and put in matrix format:
cif2.025 &lt;- apply(bart2$cif.test, 2, quantile, probs = 0.025) 
cif2.025 &lt;- matrix(cif2.025, nrow=nrow(xtest), byrow = TRUE)
cif2.975 &lt;- apply(bart2$cif.test, 2, quantile, probs = 0.975) 
cif2.975 &lt;- matrix(cif2.975, nrow=nrow(xtest), byrow = TRUE)</code></pre>
<p>We show CIF curves for patient 1 (red) and 2 (blue) in the test set
along with its corresponding credible intervals:</p>
<pre class="r"><code>par(mar = c(4, 4, 2, 0.1))

plot(bart2$times,
     cif2.pred[1,],
     type = &quot;l&quot;,
     col = &quot;red&quot;,
     ylim = c(0, 1),
     xlab = &quot;Time (years)&quot;,
     ylab = &quot;Cumulative incidence&quot;)
points(bart2$times,cif2.025[1,], col = &quot;red&quot;, type =&#39;s&#39;, lwd = 1, lty = 2)
points(bart2$times,cif2.975[1,], col = &quot;red&quot;, type = &#39;s&#39;, lwd = 1, lty = 2)
lines(bart2$times,  cif2.pred[2,], col=&quot;blue&quot;)
points(bart2$times,cif2.025[2,], col = &quot;blue&quot;, type =&#39;s&#39;, lwd = 1, lty = 2)
points(bart2$times,cif2.975[2,], col = &quot;blue&quot;, type = &#39;s&#39;, lwd = 1, lty = 2)</code></pre>
<p><img src="Discrete_specification_files/figure-html/unnamed-chunk-18-1.png" width="576" /></p>
<p>Below, we show predictions for 5 subjects in a new dataset
(e.g. <code>hd_test</code>) at a specific time point (e.g. <span
class="math inline">\(t=5\)</span> years). Note that predictions are
only provided for time-points present in the training set.</p>
<pre class="r"><code>BART2.pred &lt;- matrix(bart2$cif.test.mean, nrow=nrow(xtest), byrow = TRUE )
BART2.pred[1:5, which(bart2$times == 5)]
#&gt; [1] 0.3103403 0.3376088 0.2854426 0.3364716 0.3155569</code></pre>
<p>Note that the estimates of the 2 model formulations differ. The next
plots compare CIFs for patient 1, under the 2 different models to show
such differences:</p>
<pre class="r"><code>plot(bart1$times,cif.pred[1,],lwd=2,type=&quot;l&quot;, col=&quot;#009999&quot;, ylim=c(0,1), 
     main=&quot;Comparison of different formulations for test patient 1&quot;,
     xlab=&quot;Time&quot;, ylab=&quot;CIF(t)&quot;)
lines(bart1$times, cif2.pred[2,], col=&quot;#FFCC00&quot;,lwd=3)
      legend(&quot;topright&quot;, 
       legend=c(&quot;Formulation 1&quot;, &quot;Formulation 2&quot;),
       col=c(&quot;#009999&quot;, &quot;#FFCC00&quot;), lty=c(1,1))</code></pre>
<p><img src="Discrete_specification_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
</div>
</div>
<div id="storing-predictions" class="section level1">
<h1>Storing predictions</h1>
<p>In order to allow comparison with the predictions generated by other
methods, we save the predictions obtained in this vignette.</p>
<pre class="r"><code>pred_BART &lt;- data.frame(&quot;testID&quot; = seq_len(nrow(hd_test)),
                      &quot;crisk2.bart&quot; = BART1.pred[, which(bart1$times == 5)],
                      &quot;crisk2.bart_dart&quot; = DART1.pred[, which(dart1$times == 5)],
                      &quot;crisk.bart&quot; = BART2.pred[, which(bart1$times == 5)])
if (file.exists(&quot;/.dockerenv&quot;)){ # running in docker
  write.csv(pred_BART, &quot;/Outputs/pred_BART.csv&quot;, row.names = FALSE)
} else {
  write.csv(pred_BART, &quot;../Outputs/pred_BART.csv&quot;, row.names = FALSE)
}</code></pre>
</div>
<div id="references" class="section level1">
<h1>References</h1>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Bart2020" class="csl-entry">
Sparapani, Rodney, Brent R Logan, Robert E McCulloch, and Purushottam W
Laud. 2020. <span>“Nonparametric Competing Risks Analysis Using
<span>B</span>ayesian Additive Regression Trees.”</span> <em>Statistical
Methods in Medical Research</em> 29 (1): 57–77. <a
href="https://doi.org/10.1177/0962280218822140">https://doi.org/10.1177/0962280218822140</a>.
</div>
<div id="ref-sparapani2021" class="csl-entry">
Sparapani, Rodney, Charles Spanbauer, and Robert McCulloch. 2021.
<span>“Nonparametric Machine Learning and Efficient Computation with
Bayesian Additive Regression Trees: The BART r Package.”</span>
<em>Journal of Statistical Software</em> 97: 1–66.
</div>
</div>
</div>
<div id="session-info" class="section level1">
<h1>Session Info</h1>
<pre class="r"><code>sessionInfo()
#&gt; R version 4.3.1 (2023-06-16)
#&gt; Platform: aarch64-unknown-linux-gnu (64-bit)
#&gt; Running under: Ubuntu 22.04.3 LTS
#&gt; 
#&gt; Matrix products: default
#&gt; BLAS:   /usr/lib/aarch64-linux-gnu/openblas-pthread/libblas.so.3 
#&gt; LAPACK: /usr/lib/aarch64-linux-gnu/openblas-pthread/libopenblasp-r0.3.20.so;  LAPACK version 3.10.0
#&gt; 
#&gt; locale:
#&gt;  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
#&gt;  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
#&gt;  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
#&gt;  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
#&gt;  [9] LC_ADDRESS=C               LC_TELEPHONE=C            
#&gt; [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       
#&gt; 
#&gt; time zone: Etc/UTC
#&gt; tzcode source: system (glibc)
#&gt; 
#&gt; attached base packages:
#&gt; [1] parallel  stats     graphics  grDevices utils     datasets  methods  
#&gt; [8] base     
#&gt; 
#&gt; other attached packages:
#&gt;  [1] BART_2.9.4                nlme_3.1-162             
#&gt;  [3] nnet_7.3-19               table1_1.4.3             
#&gt;  [5] pander_0.6.5              mboost_2.9-7             
#&gt;  [7] stabs_0.6-4               glmnet_4.1-8             
#&gt;  [9] Matrix_1.6-1              pec_2023.04.12           
#&gt; [11] rms_6.7-0                 Hmisc_5.1-0              
#&gt; [13] patchwork_1.1.3           lubridate_1.9.2.9000     
#&gt; [15] forcats_1.0.0             stringr_1.5.0            
#&gt; [17] dplyr_1.1.2               purrr_1.0.2              
#&gt; [19] tidyr_1.3.0               tibble_3.2.1             
#&gt; [21] ggplot2_3.4.3             tidyverse_2.0.0          
#&gt; [23] coda_0.19-4               DPWeibull_1.8            
#&gt; [25] timereg_2.0.5             pseudo_1.4.3             
#&gt; [27] geepack_1.3.9             KMsurv_0.1-5             
#&gt; [29] riskRegression_2023.03.22 prodlim_2023.08.28       
#&gt; [31] cmprsk_2.2-11             survival_3.5-5           
#&gt; [33] splitstackshape_1.4.8     readr_2.1.4              
#&gt; 
#&gt; loaded via a namespace (and not attached):
#&gt;  [1] gridExtra_2.3       sandwich_3.0-2      rlang_1.1.1        
#&gt;  [4] magrittr_2.0.3      multcomp_1.4-25     polspline_1.1.23   
#&gt;  [7] compiler_4.3.1      systemfonts_1.0.4   vctrs_0.6.3        
#&gt; [10] quadprog_1.5-8      quantreg_5.97       shape_1.4.6        
#&gt; [13] pkgconfig_2.0.3     crayon_1.5.2        fastmap_1.1.1      
#&gt; [16] backports_1.4.1     inum_1.0-5          labeling_0.4.3     
#&gt; [19] utf8_1.2.3          rmarkdown_2.24      tzdb_0.4.0         
#&gt; [22] ragg_1.2.5          MatrixModels_0.5-2  bit_4.0.5          
#&gt; [25] xfun_0.40           cachem_1.0.8        jsonlite_1.8.7     
#&gt; [28] highr_0.10          broom_1.0.5         cluster_2.1.4      
#&gt; [31] R6_2.5.1            bslib_0.5.1         stringi_1.7.12     
#&gt; [34] parallelly_1.36.0   rpart_4.1.19        jquerylib_0.1.4    
#&gt; [37] numDeriv_2016.8-1.1 Rcpp_1.0.11         iterators_1.0.14   
#&gt; [40] knitr_1.43          future.apply_1.11.0 zoo_1.8-12         
#&gt; [43] base64enc_0.1-3     nnls_1.4            timechange_0.2.0   
#&gt; [46] splines_4.3.1       tidyselect_1.2.0    rstudioapi_0.15.0  
#&gt; [49] yaml_2.3.7          partykit_1.2-20     codetools_0.2-19   
#&gt; [52] listenv_0.9.0       lattice_0.21-8      withr_2.5.0        
#&gt; [55] evaluate_0.21       foreign_0.8-84      future_1.33.0      
#&gt; [58] pillar_1.9.0        checkmate_2.2.0     foreach_1.5.2      
#&gt; [61] stats4_4.3.1        generics_0.1.3      vroom_1.6.3        
#&gt; [64] hms_1.1.3           munsell_0.5.0       scales_1.2.1       
#&gt; [67] globals_0.16.2      glue_1.6.2          binaryLogic_0.3.9  
#&gt; [70] tools_4.3.1         data.table_1.14.8   SparseM_1.81       
#&gt; [73] mvtnorm_1.2-3       grid_4.3.1          libcoin_1.0-9      
#&gt; [76] truncdist_1.0-2     colorspace_2.1-0    htmlTable_2.4.1    
#&gt; [79] Formula_1.2-5       cli_3.6.1           evd_2.3-6.1        
#&gt; [82] textshaping_0.3.6   fansi_1.0.4         lava_1.7.2.1       
#&gt; [85] mets_1.3.2          gtable_0.3.4        sass_0.4.7         
#&gt; [88] digest_0.6.33       TH.data_1.1-2       farver_2.1.1       
#&gt; [91] htmlwidgets_1.6.2   htmltools_0.5.6     lifecycle_1.0.3    
#&gt; [94] bit64_4.0.5         MASS_7.3-60</code></pre>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("show" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = false;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>

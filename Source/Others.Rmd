---
title: "Other methods"
author: "Karla Monterrubio-Gómez, Nathan Constantine-Cooke, and Catalina Vallejos"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: show
    toc: yes
    css: style.css
    theme: simplex
    highlight: textmate
    includes:
      in_header: head.html
      before_body: navbar.html
    self_contained: false
    toc_float:
      collapsed: no
link-citations: yes
bibliography: references.bib
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  cache = TRUE
)
```



# Dataset

In order to demonstrate the methods, we employ publicly available data. 

The dataset used here corresponds to the Hodgkin’s disease (HD) study described
in @pintilie2006competing. The dataset comprises 865 patients diagnosed with 
early stage (I or II) HD, and which were treated either with radiation (RT) or 
with radiation and chemotherapy (CMT).

The recorded data includes:

* age: Age (years)
* sex: Sex, F=female and M=Male.
* trtgiven: Treatment given, RT=Radiation, CMT=Chemotherapy and radiation
* medwidsi: Size of mediastinum involvement, N=No, S=Small, L=Large
* extranod: Extranodal disease, Y=Extranodal disease, N= Nodal disease
* clinstg: Clinical stage, 1=Stage I, 2=Stage II
* time: time to failure (years) calculated from the date of diagnosis
* status: 0=censoring, 1=relapse and 2=death.

We now load and display the structure of the HD dataset:

```{r, message=FALSE, warning=FALSE}
library(readr)
hd <- data.frame(read_csv("../Data/HD/hd.csv",
                          col_types = cols(X1 = col_skip())))
str(hd)
```

To proceed with the analysis, it is important to change the data type of sex,
trtgiven, medwidsi, and extranod from character to factor. Similarly, we convert
clinstg from numeric to factor.

```{r}
hd$sex      <- as.factor(hd$sex)
hd$trtgiven <- as.factor(hd$trtgiven)
hd$medwidsi <- as.factor(hd$medwidsi)
hd$extranod <- as.factor(hd$extranod)
hd$clinstg  <- as.factor(hd$clinstg)
```

Now, we explore the number of events for each event type:

```{r, message=FALSE}
require(pander)
pander::pander(table(hd$status))
```

Thus, we have `r length(which(hd$status==0))` censored patients, 
`r length(which(hd$status==1))` with relapse, and 
`r length(which(hd$status==2))` who died. From
now on, we assume that the event of interest is relapse, i.e. `status=1`.

In order to create a test set, we use stratified sampling to partition our
dataset into 80% for train and 20% for test.

```{r}
library(splitstackshape)
set.seed(2022)
split_data <- stratified(hd, c("status"), 0.8, bothSets = TRUE)
hd_train   <- split_data$SAMP1[,-1]
hd_test    <- split_data$SAMP2[,-1]
```

Now, we explore the number of observations per status in both train and test
set:


```{r}
pander::pander(table(hd_train$status))
```
```{r}
pander::pander(table(hd_test$status))
```

# Random survival forests

The authors of random survival forests provide an online vignette 
[here](https://www.randomforestsrc.org/articles/competing.html) 
(@HemantCompeting). The method can be fitted using the `randomForestSRC` package. 
Below we showcase how to do that.

First, in order to fit the model, both, the train and test sets should be 
converted to data.frames:

```{r}
hd_train <- as.data.frame(hd_train)
hd_test <- as.data.frame(hd_test)
```

As RSF permits, both, a cause-specific and a CIF formulation. The user should 
first determine the type of analysis of interest, and pass it on the argument 
`splitrule` in the fitter function `rfsrc()`. When the objective is to do 
identify which variables are informative for a cause-specific hazard analysis,
focusing on a *specific* cause of interest, we must set `splitrule="logrank"`. 
In contrast, if one is interested on long term predictions, 
`splitrule = "logrankCR"` is more appropriate, as it considers the CIF. Below, 
we will illustrate the use of both splitting rules. 

The argument `cause` should indicate the event type of interest to be used when
applying the splitting rule. As described in the documentation of `rfsrc()`, 
`cause` can either be specified as a single integer (`cause = 1` if the first 
event type is of interest; `cause = 2` if the second event type is of interest) 
or as a vector of non-negative weights associated to each event type (e.g. 
`cause = c(1,0)` if the first event type is of interest). If `cause` is not 
specified, the default is for the splitting rule to use an average across all 
event types. 

## Generalized log-rank splitting rule (logrank)

The model can be fit with the `rfsrc()` function in the `randomForestSRC` 
package. In order to do so, one should first create a survival time object with 
the `Surv()` function. This object will be the response variable in our 
regression model. As discussed above, we set `splitrule="logrank"` and 
`cause = c(1,0)` to obtain a cause-specific analysis for event type $k=1$. In 
order to assess variable importance, we set argument `importance="permute"`. 
Note that this can be computed after the model is fitted using the `vimp()` 
function directly. Furthermore, we set `bootstrap = by.rootand samptype = "swr"` 
to do bootstrapping with replacement.

```{r}
library(randomForestSRC)

rsf.lr <- rfsrc(Surv(time, status) ~ age + sex + trtgiven + 
                  medwidsi + extranod + clinstg, 
                data = hd_train,
                ntree = 100,
                splitrule = "logrank", 
                cause = c(1,0),          # to indicate that first event is of interest
                bootstrap = "by.root",
                samptype = "swr",        # sampling with replacement.
                importance = "random",   # other choices available, e.g. permute
                save.memory= TRUE,       # useful for big datasets
                seed = 100)

```

Note that if missing values are present, it is possible to impute them by 
setting the argument `na.action=na.impute`.

A summary of the fitted object is obtained with `print()`. 

```{r}
print(rsf.lr)
```

We can obtain the fitted trees; for instance, a plot of the fifth fitted tree 
is shown:

```{r}
plot(get.tree(rsf.lr, 5))
```

Furthermore, we can visualize the results of the fitted model with 
`plot.competing.risk()`. This command shows averaged out-of-bag ensemble for: 
CS cumulative hazard, the CIF, and the conditional probability, stratified by 
event type. In the plot below, the event of interest is shown in black.

```{r, fig.dim=c(8,6)}
plot.competing.risk(rsf.lr)
```
The output of the `rfsrc()` is rich ans contains extensive information about the
model fit. For example, we can obtain both, out-of-bag, estimates of the 
cause-specific cumulative hazard function (see `rsf.lr$chf.oob`) and the CIF 
(see `rsf.lr$cif.oob`) for each event type. These estimates are provided at the
unique observed event times (see `rsf.lr$time.interest`). 

In addition, we can visualize marginal effects for each variable in terms of 
specific quantities of interest. For example, in terms of the cumulative hazard
function of the event of interest (indicated below through `target`) at a given
time point (e.g. `time = 5` years below). 

```{r, fig.dim=c(8,6)}
plot.variable(rsf.lr, target = 1, 
              time = 5,
              surv.type = "chf", 
              sorted = TRUE)
```

In order to do variable selection, a variable importance measure for the event 
of interest is shown below. The higher the value, the better. Negative values 
indicate no predictive ability.

```{r}
rsf.lr$importance[,1]
```

In addition, one can also use minimal depth variable selection. In this case, 
the smaller the value, the more predictive ability. The second column of the 
table below shows the results:

```{r}
var.mindepth  <- var.select(rsf.lr, 
                        cause = 1, 
                        method = "md", # is possible to select "vh.vimp" for variable importance measure
                        conservative = "medium" # level of conservativeness of the thresholding rule
           )  

pander::pander(var.mindepth$varselect)
```

Finally, whilst it is possible to obtain predictions for a test dataset using 
the `predict()` function, we do not do this here as `splitrule = "logrankCR"`
is instead recommended when the purpose of the analysis is to perform prediction. 


## Modified Gray’s test splitting rule (logrankCR)

In the code below, the settings of `rfsrc()` have been specified in the same
way as in the previous section (except for `splitrule`). In particular, we use
`cause = c(1,0)` to indicate that the first event type is of primary interest.

```{r}
rsf.lrCR <- rfsrc(Surv(time, status) ~ age + sex + trtgiven + 
                    medwidsi + extranod + clinstg, 
                data = hd_train,
                ntree = 100,
                splitrule = "logrankCR", 
                cause = c(1,0),          # to indicate that first event is of interest
                bootstrap = "by.root",
                samptype = "swr",        # sampling with replacement.
                importance = "random",   # other choices available, e.g. permute
                save.memory= TRUE,       # useful for big datasets
                seed = 100
                )

print(rsf.lrCR)
```

As before fitted trees can be obtained with `get.tree`.

```{r}
plot(get.tree(rsf.lrCR, 5))
```

Similarly, one can visualize the results of the fitted model with 
`plot.competing.risk()`, which shows 3 plots: a CS cumulative hazard, the CIF, 
and the conditional probability, stratified by event type. In the plot below, 
the event of interest is shown in black.

```{r, fig.dim=c(8,6)}
plot.competing.risk(rsf.lrCR)
```

In addition, we can visualize marginal effects according to the expected number 
of years lost due to the event specific cause.

```{r, fig.dim=c(8,6)}
plot.variable(rsf.lrCR, target = 1,
              surv.type = "years.lost", 
              sorted = TRUE)
```

In order to do variable selection, as variable importance measure for the event 
of interest is shown below. The higher the value, the better. Negative values 
indicate no predictive ability.

```{r}
rsf.lrCR$importance[,1]
```

In order to obtain predictions in the test set, we employ `predict()` function 
as shown below. A summary of the object is shown with the function `print()`

```{r}
test.lrCR <- predict(rsf.lrCR, 
                   newdata = hd_test,
                   importance = "permute"  #VIM can also be obtained at this stage
                   )
print(test.lrCR)
```

The CIF for patient 1 and 2 in the test set is shown:   

```{r, fig.dim=c(6,4)}
par(mar = c(4, 4, 2, 0.1))

plot(test.lrCR$time.interest,
     test.lrCR$cif[1,,1], 
     type = "l",
     col = "red",
     ylim = c(0, 0.6),
     xlab = "Time (years)",
     ylab = "Cumulative incidence")
lines(test.lrCR$time.interest,  test.lrCR$cif[2,,1], #CIF.hat[2,], 
      col="blue")
legend("topright", legend = c("Patient 1", "Patient 2"),
       lty = c(1,1), col = c("red", "blue"))
```


Predicted CIF at $t=5$ for the first 5 subjects in the test set are shown:
```{r}
test.lrCR$cif[1:5, test.lrCR$time.interest==5,1]
```


A similar analysis can be performed using an average between both event types
as the target for the splitting rule. To do so, `cause` can be left unspecified
or be set to `cause = c(0.5, 0.5)`. 

```{r}
rsf.lrCR.av <- rfsrc(Surv(time, status) ~ age + sex + trtgiven + 
                    medwidsi + extranod + clinstg, 
                data = hd_train,
                ntree = 100,
                splitrule = "logrankCR", 
                bootstrap = "by.root",
                samptype = "swr",        # sampling with replacement.
                importance = "random",   # other choices available, e.g. permute
                save.memory= TRUE,       # useful for big datasets
                seed = 100
                )

print(rsf.lrCR.av)
```

Using this approach, predictions for the test dataset are obtained as follows:

```{r}
test.lrCR.av <- predict(rsf.lrCR.av, 
                   newdata = hd_test,
                   importance = "permute"  #VIM can also be obtained at this stage
                   )
print(test.lrCR.av)
```

As before, here we visualise the CIF for the first two patients in the test set:

```{r, fig.dim=c(6,4)}
par(mar = c(4, 4, 2, 0.1))

plot(test.lrCR.av$time.interest,
     test.lrCR.av$cif[1,,1], 
     type = "l",
     col = "red",
     ylim = c(0, 0.6),
     xlab = "Time (years)",
     ylab = "Cumulative incidence")
lines(test.lrCR.av$time.interest,  test.lrCR.av$cif[2,,1], #CIF.hat[2,], 
      col="blue")
legend("topright", legend = c("Patient 1", "Patient 2"),
       lty = c(1,1), col = c("red", "blue"))
```
Finally, CIF estimates at $t=5$ for the first 5 subjects in the test 
set are shown:

```{r}
test.lrCR.av$cif[1:5, test.lrCR.av$time.interest==5,1]
```


# Storing predictions

In order to allow comparison with the predictions generated by other methods,
we save the predictions obtained in this vignette.  

```{r save_pred}
pred_Others <- data.frame(
  "testID" = seq_len(nrow(hd_test)),
  "RF_logrankCR" = test.lrCR$cif[,test.lrCR$time.interest==5,1],
  "RF_logrankCR.av" = test.lrCR.av$cif[,test.lrCR.av$time.interest==5,1])
write.csv(pred_Others, "../Predictions/pred_Others.csv", row.names = FALSE)
```


# References
<div id="refs"></div>

# Session Info
```{r}
sessionInfo()
```
